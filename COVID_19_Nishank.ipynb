{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID-19_Nishank",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CheMLers/covid-19/blob/master/COVID_19_Nishank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJf8ueueCPK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ2JwGKovY0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -U keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fLw-E5J13dD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Internation Time Series data**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJjL2qItvNaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import math\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.python.keras.layers import Dense, LSTM\n",
        "#from tensorflow.python.keras import Sequential\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "np.random.seed(7)\n",
        "\n",
        "# source = https://github.com/datasets/covid-19/edit/master/data/time-series-19-covid-combined.csv\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/google collab/COVID-19_Nishank/data.csv')\n",
        "data = data[[\"Date\",\"Country/Region\",\"Province/State\",\"Confirmed\",\"Recovered\",\"Deaths\"]]\n",
        "aggregated_data = data.groupby([\"Date\"]).sum()\n",
        "india_data = data[data[\"Country/Region\"] == \"India\"]\n",
        "india_data = india_data.groupby([\"Date\"]).sum()\n",
        "italy_data = data[data[\"Country/Region\"] == \"Italy\"]\n",
        "italy_data = italy_data.groupby([\"Date\"]).sum()\n",
        "\n",
        "data = aggregated_data[\"Confirmed\"]\n",
        "dataX = dataY = data\n",
        "dataX = dataX[:-1]\n",
        "dataY = dataY[1:]\n",
        "dataX = dataX.to_numpy()\n",
        "dataY = dataY.to_numpy()\n",
        "dataX = dataX.reshape(len(dataY),1)\n",
        "dataY = dataY.reshape(len(dataY),1)\n",
        "\n",
        "trainX = dataX[:int(0.9*len(dataX))]\n",
        "testX = dataX[int(0.9*len(dataX)):]\n",
        "trainY = dataY[:int(0.9*len(dataX))]\n",
        "testY = dataY[int(0.9*len(dataX)):] \n",
        "\n",
        "scalerX=MinMaxScaler(feature_range=(0,1))\n",
        "trainX = scalerX.fit_transform(trainX)\n",
        "testX = scalerX.transform(testX)\n",
        "scalerY=MinMaxScaler(feature_range = (0,1))\n",
        "trainY = scalerY.fit_transform(trainY)\n",
        "testY = scalerY.transform(testY)\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 256, input_shape=(1, 1)))\n",
        "#model.add(Dense(units = 4))\n",
        "model.add(Dense(units = 128))\n",
        "model.add(Dense(units = 64))\n",
        "model.add(Dense(units = 32))\n",
        "model.add(Dense(units = 1, activation = \"linear\"))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=200, batch_size=1, verbose=0 , validation_split=0.1)\n",
        "\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "# invert predictions\n",
        "trainPredict = scalerY.inverse_transform(trainPredict)\n",
        "trainY = scalerY.inverse_transform(trainY)\n",
        "testPredict = scalerY.inverse_transform(testPredict)\n",
        "testY = scalerY.inverse_transform(testY)\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(trainY[:,0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(testY[:,0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty((len(dataY)+1,1))\n",
        "trainPredictPlot[:,0] = np.nan\n",
        "trainPredictPlot[0:len(trainPredict),0] = trainPredict[:,0]\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty((len(dataY)+1,1))\n",
        "testPredictPlot[:,0] = np.nan\n",
        "testPredictPlot[len(trainPredict):len(dataY),0] = testPredict[:,0]\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataY)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMASeAQet2OC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**India Data Analysis for best architecture till now**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn7O2K1TzuS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "np.random.seed(7)\n",
        "\n",
        "# source = https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml#\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/google collab/COVID-19_Nishank/India_data.txt', delimiter = '\\s+')\n",
        "\n",
        "data_confirmed = data[data[\"Status\"] == \"Confirmed\"]\n",
        "data_confirmed = data_confirmed.drop([\"Date\",\"Status\"],axis = 1)\n",
        "data_confirmed = data_confirmed.reset_index()\n",
        "data_confirmed = data_confirmed.drop([\"index\"],axis = 1)\n",
        "data_confirmed = data_confirmed.fillna(0)\n",
        "data_confirmed_cum = data_confirmed.cumsum()\n",
        "#data_confirmed_cum = data_confirmed_cum.stack().groupby(level=0).nlargest(10).unstack().reset_index(level=1, drop=True).reindex(columns=data_confirmed_cum.columns).fillna(0)\n",
        "\n",
        "#dataX = data_confirmed_cum.drop([\"TT\"],axis = 1)\n",
        "dataX = data_confirmed_cum[\"TT\"]\n",
        "dataY = data_confirmed_cum[\"TT\"]\n",
        "dataX = dataX[:-1]\n",
        "dataY = dataY[1:]\n",
        "dataX = dataX.to_numpy()\n",
        "dataY = dataY.to_numpy()\n",
        "dataX = dataX.reshape(len(dataY),1)\n",
        "dataY = dataY.reshape(len(dataY),1)\n",
        "\n",
        "trainX = dataX[:int(0.8*len(dataX))]\n",
        "testX = dataX[int(0.8*len(dataX)):]\n",
        "trainY = dataY[:int(0.8*len(dataX))]\n",
        "testY = dataY[int(0.8*len(dataX)):] \n",
        "\n",
        "scalerX=MinMaxScaler(feature_range=(0,1))\n",
        "trainX = scalerX.fit_transform(trainX)\n",
        "testX = scalerX.transform(testX)\n",
        "scalerY=MinMaxScaler(feature_range = (0,1))\n",
        "trainY = scalerY.fit_transform(trainY)\n",
        "testY = scalerY.transform(testY)\n",
        "\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 256, input_shape=(1, 1)))\n",
        "model.add(Dense(units = 128))\n",
        "model.add(Dense(units = 64))\n",
        "model.add(Dense(units = 32))\n",
        "model.add(Dense(units = 1, activation = \"linear\"))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=200, batch_size=1, verbose=0 , validation_split=0.1)\n",
        "model.save(\"/content/drive/My Drive/google collab/COVID-19_Nishank/best_india_model.h5\")\n",
        "#model = load_model('/content/drive/My Drive/google collab/COVID-19_Nishank/best_india_model.h5')\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "# invert predictions\n",
        "trainPredict = scalerY.inverse_transform(trainPredict)\n",
        "trainY = scalerY.inverse_transform(trainY)\n",
        "testPredict = scalerY.inverse_transform(testPredict)\n",
        "testY = scalerY.inverse_transform(testY)\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(trainY[:,0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(testY[:,0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty((len(dataY)+1,1))\n",
        "trainPredictPlot[:,0] = np.nan\n",
        "trainPredictPlot[0:len(trainPredict),0] = trainPredict[:,0]\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty((len(dataY)+1,1))\n",
        "testPredictPlot[:,0] = np.nan\n",
        "testPredictPlot[len(trainPredict):len(dataY),0] = testPredict[:,0]\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataY)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeFiiz5FUCE2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Code with predictor function for future days as well**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ypnsahZVF8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "np.random.seed(7)\n",
        "\n",
        "def predictor(data,days,split):\n",
        "  dataX = data\n",
        "  dataY = data\n",
        "\n",
        "  dataX = dataX[:-1]\n",
        "  dataY = dataY[1:]\n",
        "  dataX = dataX.to_numpy()\n",
        "  dataY = dataY.to_numpy()\n",
        "  dataX = dataX.reshape(len(dataY),1)\n",
        "  dataY = dataY.reshape(len(dataY),1)\n",
        "\n",
        "  trainX = dataX[:int(split*len(dataX))]\n",
        "  testX = dataX[int(split*len(dataX)):]\n",
        "  trainY = dataY[:int(split*len(dataX))]\n",
        "  testY = dataY[int(split*len(dataX)):] \n",
        "\n",
        "  scalerX=MinMaxScaler(feature_range=(0,1))\n",
        "  trainX = scalerX.fit_transform(trainX)\n",
        "  testX = scalerX.transform(testX)\n",
        "  scalerY=MinMaxScaler(feature_range = (0,1))\n",
        "  trainY = scalerY.fit_transform(trainY)\n",
        "  testY = scalerY.transform(testY)\n",
        "\n",
        "  trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "  testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units = 256, input_shape=(1, 1)))\n",
        "  model.add(Dense(units = 128))\n",
        "  model.add(Dense(units = 64))\n",
        "  model.add(Dense(units = 32))\n",
        "  model.add(Dense(units=16))\n",
        "  model.add(Dense(units = 1, activation = \"linear\"))\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  model.fit(trainX, trainY, epochs=200, batch_size=1, verbose=0 , validation_split=0.2)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.title(\"Training Data only\")\n",
        "  trainPredict = scalerY.inverse_transform(model.predict(trainX))\n",
        "  predict = model.predict(testX)\n",
        "  testPredict = scalerY.inverse_transform(predict)\n",
        "\n",
        "  trainPredictPlot = np.empty((len(dataY),1))\n",
        "  trainPredictPlot[:,0] = np.nan\n",
        "  trainPredictPlot[0:len(trainPredict),0] = trainPredict[:,0]\n",
        "  # shift test predictions for plotting\n",
        "  testPredictPlot = np.empty((len(dataY)+1,1))\n",
        "  testPredictPlot[:,0] = np.nan\n",
        "  testPredictPlot[len(trainPredict):len(dataY),0] = testPredict[:,0]\n",
        "  # plot baseline and predictions\n",
        "  plt.plot(dataY)\n",
        "  plt.plot(trainPredictPlot)\n",
        "  plt.plot(testPredictPlot)\n",
        "  plt.show()\n",
        "\n",
        "  model.fit(testX,testY,epochs = 30, batch_size = 1, verbose=0,validation_split = 0.1)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.title(\"Full Data\")\n",
        "  trainPredict = scalerY.inverse_transform(model.predict(trainX))\n",
        "  predict = model.predict(testX)\n",
        "  testPredict = scalerY.inverse_transform(predict)\n",
        "\n",
        "  trainPredictPlot = np.empty((len(dataY),1))\n",
        "  trainPredictPlot[:,0] = np.nan\n",
        "  trainPredictPlot[0:len(trainPredict),0] = trainPredict[:,0]\n",
        "  # shift test predictions for plotting\n",
        "  testPredictPlot = np.empty((len(dataY),1))\n",
        "  testPredictPlot[:,0] = np.nan\n",
        "  testPredictPlot[len(trainPredict):len(dataY),0] = testPredict[:,0]\n",
        "  # plot baseline and predictions\n",
        "  plt.plot(dataY)\n",
        "  plt.plot(trainPredictPlot)\n",
        "  plt.plot(testPredictPlot)\n",
        "\n",
        "  futurePredictPlot = np.empty(len(dataY)-1)\n",
        "  futurePredictPlot[:] = np.nan\n",
        "  futurePredictPlot = np.append(futurePredictPlot,testPredict[-1:,0])\n",
        "\n",
        "  for i in range(days):\n",
        "    future_pred = dataY[-1:]\n",
        "    future_pred = np.reshape(future_pred,(1,1))\n",
        "    future_pred = scalerX.transform(future_pred)\n",
        "    future_pred = np.reshape(future_pred, (future_pred.shape[0], 1, future_pred.shape[1]))\n",
        "    futurePredictPlot = np.append(futurePredictPlot,scalerY.inverse_transform(model.predict(future_pred)))\n",
        "    print(scalerY.inverse_transform(model.predict(future_pred)))\n",
        "    trainX = future_pred\n",
        "    trainY = np.reshape(model.predict(future_pred),(1,1))\n",
        "    model.fit(trainX,trainY,epochs = 2, verbose = 0)\n",
        "    dataY = np.append(dataY,scalerY.inverse_transform(model.predict(future_pred)))\n",
        "  \n",
        "  plt.plot(futurePredictPlot)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTUJOhxYWYhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# source = https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml#\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/google collab/COVID-19_Nishank/India_data.txt', delimiter = '\\s+')\n",
        "\n",
        "data_confirmed = data[data[\"Status\"] == \"Confirmed\"]\n",
        "data_confirmed = data_confirmed.drop([\"Date\",\"Status\"],axis = 1)\n",
        "data_confirmed = data_confirmed.reset_index()\n",
        "data_confirmed = data_confirmed.drop([\"index\"],axis = 1)\n",
        "data_confirmed = data_confirmed.fillna(0)\n",
        "data_confirmed_cum = data_confirmed.cumsum()\n",
        "predictor(data_confirmed_cum[\"TT\"],1,0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmEYkQApZosb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Predictor function with added parameter of lookback**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9e5mgkMZyMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agpZd1GVGNfn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Growth rate vs Confirmed cases Parabolic analysis**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBLW5c2lozDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import math\n",
        "#import tensorflow as tf\n",
        "#from tensorflow.python.keras.layers import Dense, LSTM\n",
        "#from tensorflow.python.keras import Sequential\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "np.random.seed(7)\n",
        "\n",
        "# source = https://github.com/datasets/covid-19/edit/master/data/time-series-19-covid-combined.csv\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/google collab/COVID-19_Nishank/data.csv')\n",
        "data = data[[\"Date\",\"Country/Region\",\"Province/State\",\"Confirmed\",\"Recovered\",\"Deaths\"]]\n",
        "aggregated_data = data.groupby([\"Date\"]).sum()\n",
        "india_data = data[data[\"Country/Region\"] == \"India\"]\n",
        "india_data = india_data.groupby([\"Date\"]).sum()\n",
        "italy_data = data[data[\"Country/Region\"] == \"Italy\"]\n",
        "italy_data = italy_data.groupby([\"Date\"]).sum()\n",
        "#italy_data = aggregated_data\n",
        "italy_data = italy_data[\"Confirmed\"]\n",
        "italy_data_diff = italy_data.diff()\n",
        "#plt.plot(italy_data,italy_data_diff)\n",
        "dataX = italy_data\n",
        "dataY = italy_data_diff\n",
        "dataX = dataX[:-1]\n",
        "dataY = dataY[1:]\n",
        "dataX = dataX.to_numpy()\n",
        "dataY = dataY.to_numpy()\n",
        "\n",
        "trainX = dataX[:int(0.9*len(dataX))]\n",
        "testX = dataX[int(0.9*len(dataX)):]\n",
        "trainY = dataY[:int(0.9*len(dataX))]\n",
        "testY = dataY[int(0.9*len(dataX)):] \n",
        "\n",
        "a = np.polyfit(trainX, trainY, 2)\n",
        "b = np.poly1d(a)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(dataY)\n",
        "plt.plot(b(dataX))\n",
        "#plt.plot(b(testX))\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(dataY.cumsum())\n",
        "plt.plot(b(dataX).cumsum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QLQlXpjrfjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}